{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_friedman2\n",
    "from sklearn.datasets import make_friedman3\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from skrvm import RVR\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def EM_re_estimation(self, n_iterations, likelihood=float('inf')):\n",
    "        gamma = np.array([0.] * self.kernel_m)\n",
    "        w_mp = np.matrix([[]])\n",
    "        t_matrix = np.matrix(self.data_t)\n",
    "\n",
    "        last = self.marginal_likelihood()\n",
    "        cur = last\n",
    "        print(\"FIRST LIKELIHOOD = \", last)\n",
    "        iterations_number = 0\n",
    "        log_proba = [cur]\n",
    "        relevant_vectors_number = [self.kernel_m]\n",
    "\n",
    "        # for k in range(n_iterations):\n",
    "        while cur < likelihood and iterations_number < n_iterations:\n",
    "            last = cur\n",
    "            iterations_number += 1\n",
    "\n",
    "            tmp_m = self.betta * (self.F.T * self.F) + np.matrix(np.diag(self.alpha))\n",
    "            sigma = np.linalg.inv(self.betta * (self.F.T * self.F) + np.matrix(np.diag(self.alpha)))\n",
    "            w_mp = sigma * self.F.T * (self.betta * t_matrix)\n",
    "            for j in range(self.kernel_m):\n",
    "                if np.abs(w_mp.A[j]) < self.weight_bound or np.abs(self.alpha[j]) > self.alpha_bound:\n",
    "                    w_mp.A[j] = 0\n",
    "                    self.alpha[j] = 1e200\n",
    "                    gamma[j] = 0\n",
    "                else:\n",
    "                    gamma[j] = 1 - self.alpha[j] * sigma.A[j][j]\n",
    "                    self.alpha[j] = 1 / (w_mp.A[j][0] ** 2 + sigma.A[j][j])\n",
    "\n",
    "            self.betta = (self.N) / (np.linalg.norm(t_matrix - self.F * np.matrix(w_mp)) ** 2\n",
    "                                     + sum(gamma) / self.betta)\n",
    "\n",
    "            cur = self.marginal_likelihood()\n",
    "#             print(cur - last, cur, iterations_number)\n",
    "            \n",
    "            log_proba.append(cur)\n",
    "            relevant_vectors_number.append((np.abs(w_mp) > self.eps).sum())\n",
    "\n",
    "        print(iterations_number, \"\\nLIKELIHOOD\", last)\n",
    "        self.w = w_mp\n",
    "\n",
    "        return log_proba, relevant_vectors_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "from scipy.linalg import logm, expm\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics.pairwise import rbf_kernel, linear_kernel, polynomial_kernel \n",
    "\n",
    "class RVMRegression(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"RVM Regression class\"\"\"\n",
    "    fitted = False\n",
    "    alpha = None\n",
    "    betta = None\n",
    "    kernel = 'linear'\n",
    "    data_x = None\n",
    "    data_t = None\n",
    "    alpha_bound = 10**12\n",
    "    weight_bound = 10**-3\n",
    "    number_of_iterations = 100\n",
    "    F = None\n",
    "    kernel_m = None\n",
    "    D = 0\n",
    "    w = None\n",
    "    inv_a = None\n",
    "    N = 0\n",
    "    eps = 1e-3\n",
    "    lokelihood_eps = 1e-4\n",
    "\n",
    "    def __init__(self, algorithm='tipping', learning_rate=0.1, alpha=None, betta=None, \n",
    "                 kernel='rbf', coef0=0, gamma=1, degree=2, number_of_iterations=5000,\n",
    "                 bias_used=True, betta_fixed=False, calc_prob=False):\n",
    "        if alpha:\n",
    "            self.alpha = alpha\n",
    "\n",
    "        if betta:\n",
    "            self.betta = betta\n",
    "\n",
    "        self.algorithm = algorithm\n",
    "        self.coef0 = coef0\n",
    "        self.degree = degree\n",
    "        self.gamma = gamma\n",
    "        self.kernel = kernel\n",
    "        self.number_of_iterations = number_of_iterations\n",
    "        self.relevance_w = np.array([])\n",
    "        self.relevance_x = np.array([])\n",
    "        self.relevance_y = np.array([])\n",
    "        self.learning_rate = learning_rate\n",
    "        self.bias_used = bias_used\n",
    "        self.betta_fixed = betta_fixed\n",
    "        self.calc_prob = calc_prob\n",
    "\n",
    "    def tipping_re_estimation(self, n_iterations):\n",
    "        gamma = np.zeros(self.kernel_m)\n",
    "        t = self.data_t.reshape((-1,))\n",
    "\n",
    "        last = self.marginal_likelihood()\n",
    "        cur = last\n",
    "#         print(\"FIRST = \", last)\n",
    "        iterations_number = 0\n",
    "        log_proba = [cur]\n",
    "        relevant_vectors_number = [self.kernel_m]\n",
    "\n",
    "\n",
    "        for k in range(n_iterations):\n",
    "            last = cur\n",
    "            iterations_number += 1\n",
    "\n",
    "            sigma = np.linalg.inv(self.betta * np.dot(self.F.T, self.F) + np.diag(self.alpha))\n",
    "            w_mp = self.betta * np.dot(sigma, np.dot(self.F.T, t))\n",
    "            \n",
    "            alpha_old = self.alpha.copy()\n",
    "            \n",
    "            if self.algorithm == 'tipping':\n",
    "                gamma = 1 - self.alpha * np.diag(sigma)\n",
    "                self.alpha = gamma / (w_mp ** 2)\n",
    "\n",
    "            elif self.algorithm == 'EM':\n",
    "                self.alpha[j] = 1 / (w_mp ** 2 + np.diag(sigma))\n",
    "            else:\n",
    "                print('No such algorithm')\n",
    "                \n",
    "            \n",
    "            if self.algorithm == 'tipping' and not self.betta_fixed:\n",
    "                # ОПАСНО!!!!\n",
    "                self.betta = (self.N - np.sum(gamma)) / (np.linalg.norm(t - np.dot(self.F, w_mp)) ** 2)\n",
    "            elif self.algorithm == 'EM' and not self.betta_fixed:\n",
    "                self.betta = (self.N) / (np.linalg.norm(t - np.dot(self.F, w_mp)) ** 2\n",
    "                                         + sum(gamma) / self.betta)\n",
    "            elif not self.betta_fixed:\n",
    "                print('No such algorithm')\n",
    "                \n",
    "            \n",
    "            rel_ind = self.alpha < self.alpha_bound\n",
    "            \n",
    "            self.alpha = self.alpha[rel_ind]\n",
    "            gamma = gamma[rel_ind]\n",
    "            w_mp = w_mp[rel_ind]\n",
    "            self.F = self.F[:, rel_ind]\n",
    "            sigma = sigma[np.ix_(rel_ind, rel_ind)]\n",
    "            \n",
    "            if self.bias_used:\n",
    "                if not rel_ind[-1]:\n",
    "                    self.bias_used = False\n",
    "                self.relevance_x = self.relevance_x[rel_ind[:-1]]\n",
    "            else:\n",
    "                self.relevance_x = self.relevance_x[rel_ind]\n",
    "\n",
    "            if self.calc_prob:\n",
    "                cur = self.marginal_likelihood()\n",
    "                log_proba.append(cur)\n",
    "                print(cur, len(self.alpha))\n",
    "#             relevant_vectors_number.append((np.abs(w_mp) > self.eps).sum())\n",
    "\n",
    "        self.w = w_mp\n",
    "\n",
    "        return log_proba, relevant_vectors_number\n",
    "\n",
    "    def fit(self, x, t):\n",
    "        if len(x) == 0:\n",
    "            raise NameError(\"X array is empty!\")\n",
    "        if len(x) != len(t):\n",
    "            raise NameError(\"Different len X and t\")\n",
    "\n",
    "        self.D = x.shape[1]\n",
    "        self.N = x.shape[0]\n",
    "\n",
    "        self.kernel_m = self.N + (1 if self.bias_used else 0)\n",
    "                \n",
    "        if self.kernel == '2D ex':\n",
    "            self.kernel_m = len(x) + 4\n",
    "        \n",
    "        self.data_x = x.copy()\n",
    "        self.data_t = t.copy()\n",
    "        self.relevance_x = self.data_x\n",
    "\n",
    "        if not self.alpha:\n",
    "            self.alpha = 1\n",
    "        \n",
    "        self.alpha = np.ones(self.kernel_m) * self.alpha\n",
    "        \n",
    "        if not self.betta:\n",
    "            self.betta = 1\n",
    "\n",
    "        self.F = self._apply_kernel(self.data_x, self.data_x)\n",
    "        \n",
    "        log_prob, relevant_vectors_number = self.tipping_re_estimation(self.number_of_iterations)\n",
    "\n",
    "#         self.rel_ind = np.abs(self.w) > self.weight_bound\n",
    "        \n",
    "#         self.relevance_w = self.w[self.rel_ind]\n",
    "#         self.relevance_x = self.data_x[self.rel_ind, :]\n",
    "#         self.relevance_y = self.data_t[self.rel_ind]\n",
    "\n",
    "        return np.array(log_prob), np.array(relevant_vectors_number)\n",
    "\n",
    "    \n",
    "    def _apply_kernel(self, x, y):\n",
    "        \"\"\"Apply the selected kernel function to the data.\"\"\"\n",
    "        \n",
    "        if self.kernel == 'linear':\n",
    "            phi = linear_kernel(x, y)\n",
    "        elif self.kernel == 'rbf':\n",
    "            phi = rbf_kernel(x, y, self.gamma)\n",
    "        elif self.kernel == 'poly':\n",
    "            phi = polynomial_kernel(x, y, self.degree, self.gamma, self.coef0)\n",
    "        elif callable(self.kernel):\n",
    "            phi = self.kernel(x, y)\n",
    "            if len(phi.shape) != 2:\n",
    "                raise ValueError(\n",
    "                    \"Custom kernel function did not return 2D matrix\"\n",
    "                )\n",
    "            if phi.shape[0] != x.shape[0]:\n",
    "                raise ValueError(\n",
    "                    \"Custom kernel function did not return matrix with rows\"\n",
    "                    \" equal to number of data points.\"\"\"\n",
    "                )\n",
    "        else:\n",
    "            raise ValueError(\"Kernel selection is invalid.\")\n",
    "\n",
    "        if self.bias_used:\n",
    "            phi = np.append(phi, np.ones((phi.shape[0], 1)), axis=1)\n",
    "\n",
    "        return phi\n",
    "\n",
    "\n",
    "    def calc_sigma(self):\n",
    "        a = np.matrix(np.diag(self.alpha))\n",
    "        try:\n",
    "            inv_a = np.linalg.inv(a)\n",
    "        except np.linalg.LinAlgError:\n",
    "            inv_a = np.linalg.pinv(a)\n",
    "\n",
    "        self.inv_a = inv_a.copy()\n",
    "        e = np.matrix(np.diag([1] * a.shape[0]))\n",
    "        tmp_mat = np.linalg.pinv(e + self.betta * self.F * self.inv_a * self.F.T)\n",
    "        return self.inv_a - self.inv_a * self.betta * self.F.T * tmp_mat * self.F * self.inv_a\n",
    "\n",
    "    def predict(self, x):\n",
    "        \n",
    "        phi = self._apply_kernel(x, self.relevance_x)\n",
    "        \n",
    "        return np.dot(phi, self.w).reshape((-1,))\n",
    "            \n",
    "#     def score(self, data_x, t):\n",
    "#         pred = self.predict(data_x)\n",
    "        \n",
    "#         u = ((pred.reshape((-1,)) - t.reshape((-1,))) ** 2).sum()\n",
    "#         v = ((t.reshape((-1,)) - t.mean()) ** 2).sum()\n",
    "        \n",
    "#         return 1 - u / v\n",
    "\n",
    "    def marginal_likelihood(self, x=None):\n",
    "        if x is not None:\n",
    "            t = self.predict(x)\n",
    "        else:\n",
    "            t = self.data_t\n",
    "\n",
    "        self.inv_a = np.diag(1 / self.alpha)\n",
    "        \n",
    "        tmp = np.dot(self.F, np.dot(self.inv_a, self.F.T))\n",
    "        e = np.eye(tmp.shape[0]) / self.betta\n",
    "\n",
    "        u = e + tmp\n",
    "        tmp = np.linalg.inv(u)\n",
    "        tmp = -0.5 * np.dot(t.T, np.dot(tmp, t))\n",
    "        det = logm(u).trace()\n",
    "        tmp = tmp - np.log(2 * np.pi)*(self.N / 2) - det / 2\n",
    "        return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a05bd91f1464>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfr_2_cl_my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRVMRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rbf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfr_2_cl_my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# fr_2_cl_my.score(test_x, test_y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_x' is not defined"
     ]
    }
   ],
   "source": [
    "fr_2_cl_my = RVMRegression(kernel='rbf', gamma=1e-5, number_of_iterations=8000)\n",
    "fr_2_cl_my.fit(train_x, train_y)\n",
    "# fr_2_cl_my.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-aeaa1fee67c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfr_2_cl_my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test_x' is not defined"
     ]
    }
   ],
   "source": [
    "mean_squared_error(fr_2_cl_my.predict(test_x), test_y) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(test_x[:,1], test_y)\n",
    "plt.scatter(test_x[:,1], fr_2_cl_my.predict(test_x), c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fr_2_cl_my.F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Friedman data set')\n",
    "\n",
    "np.random.seed(2)\n",
    "n_exp = 1\n",
    "rel_vec = 0\n",
    "RMSE = 0\n",
    "for i in range(n_exp):\n",
    "    train_x, train_y = make_friedman3(240, noise=1/3)\n",
    "    fr_2_cl_em = RVMRegression(kernel=\"rbf\",gamma=1.3975104130536649e-05, algorithm='EM', number_of_iterations=100)\n",
    "    log_prob_em, rel_vec_numb_em = fr_2_cl_em.fit(train_x, train_y.reshape(-1, 1))\n",
    "    rel_vec += len(fr_2_cl_em.rel_ind)\n",
    "\n",
    "    valid_x, valid_y = make_friedman3(1000)\n",
    "    pred_y = fr_2_cl_em.predict(valid_x)\n",
    "\n",
    "    RMSE += mean_squared_error(valid_y, pred_y) ** 0.5\n",
    "\n",
    "print(\"Vectors: \", rel_vec / n_exp)\n",
    "print(\"mean square = \", RMSE / n_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_pred_em = fr_2_cl_em.predict(train_x)\n",
    "train_pred_tipping = fr_2_cl_em.predict(train_x)\n",
    "\n",
    "print(mean_squared_error(train_y, train_pred_em), mean_squared_error(train_y, train_pred_tipping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Friedman data set')\n",
    "\n",
    "np.random.seed(2)\n",
    "n_exp = 1\n",
    "rel_vec = 0\n",
    "RMSE = 0\n",
    "for i in range(n_exp):\n",
    "    train_x, train_y = make_friedman3(240, noise=0)\n",
    "    fr_2_cl_tipping = RVMRegression(kernel=\"rbf\", gamma=1.3975104130536649e-05, number_of_iterations=200)\n",
    "    log_prob_tipping, rel_vec_numb_tipping = fr_2_cl_tipping.fit(train_x, train_y.reshape(-1, 1))\n",
    "    rel_vec += len(fr_2_cl_tipping.rel_ind)\n",
    "\n",
    "    valid_x, valid_y = make_friedman3(800)\n",
    "    pred_y = fr_2_cl_tipping.predict(valid_x)\n",
    "\n",
    "    RMSE += mean_squared_error(valid_y, pred_y)\n",
    "\n",
    "print(\"Vectors: \", rel_vec / n_exp)\n",
    "print(\"RMSE = \", RMSE / n_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_prob_tipping[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_squared_error(train_y, fr_2_cl_tipping.predict(train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_x, valid_y = make_friedman3(1000)\n",
    "pred_y = fr_2_cl_tipping.predict(valid_x)\n",
    "mean_squared_error(valid_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fr_2_cl_tipping.score(valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_x, valid_y = make_friedman3(10000)\n",
    "pred_y = fr_2_cl_tipping.predict(valid_x)\n",
    "\n",
    "mean_squared_error(valid_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "cl = SVR(C=4500, kernel='rbf', gamma=4.4984326689694439e-06)\n",
    "cl.fit(train_x, train_y)\n",
    "print('score', cl.score(valid_x, valid_y))\n",
    "\n",
    "svm_pred = cl.predict(valid_x)\n",
    "print('MSE', mean_squared_error(svm_pred, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {'kernel':['rbf'], 'gamma':np.logspace(-7, 2, 10), \n",
    "              'C':np.logspace(2, 9, 10)}\n",
    "clf = GridSearchCV(SVR(), parameters)\n",
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_pred = cl.predict(valid_x)\n",
    "mean_squared_error(svm_pred, valid_y) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {'kernel':['rbf'], 'gamma':np.linspace(1.3738237958832637e-05 / 2, 1.3738237958832637e-05 * 2, 30), 'algorithm':['tipping']}\n",
    "clf = GridSearchCV(RVMRegression(), [parameters])\n",
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.best_params_, clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fr_2_cl_tipping.score(valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(valid_x[:,2], valid_y)\n",
    "plt.scatter(valid_x[:,2], svm_pred, c='r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "for i in range(n_exp):\n",
    "    boston = load_boston()\n",
    "    train_x = boston.data[:481]\n",
    "    train_y = boston.target[:481]\n",
    "\n",
    "    valid_x = boston.data[481:]\n",
    "    valid_y = boston.target[481:]\n",
    "\n",
    "    cl = RVMRegression(kernel=\"rbf\", gamma=0.0001)\n",
    "    print(train_x.shape, train_y.shape)\n",
    "    log_prob_tipping, rel_vec_numb_tipping = cl.fit(np.matrix(train_x), np.matrix(train_y.reshape(481, 1)))\n",
    "    rel_vec += len(cl.rel_ind)\n",
    "\n",
    "    pred_y = cl.predict(valid_x)\n",
    "\n",
    "    RMSE += mean_squared_error(valid_y, pred_y) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(n_exp):\n",
    "    boston = load_boston()\n",
    "    train_x = boston.data[:481]\n",
    "    train_y = boston.target[:481]\n",
    "\n",
    "    valid_x = boston.data[481:]\n",
    "    valid_y = boston.target[481:]\n",
    "\n",
    "    cl = RVMRegression(kernel=\"rbf\", gamma=0.0001, algo='EM', number_of_iterations=100)\n",
    "    print(train_x.shape, train_y.shape)\n",
    "    log_prob_em, rel_vec_numb_em = cl.fit(np.matrix(train_x), np.matrix(train_y.reshape(481, 1)))\n",
    "    rel_vec += len(cl.rel_ind)\n",
    "\n",
    "    pred_y = cl.predict(valid_x)\n",
    "\n",
    "    RMSE += mean_squared_error(valid_y, pred_y) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rel_vec_numb_em[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k, n = 1, 100\n",
    "x1 = log_prob_tipping[k:n]\n",
    "x2 = log_prob_em[k:n]\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, sharex=True)\n",
    "\n",
    "f.suptitle('Boston Housing data set', fontsize=14, fontweight='bold')\n",
    "# plt.subplot(2, 1, 1, sharex=True)\n",
    "ax1.plot(np.arange(len(x1)) + k, x1, 'g-', label=\"Tipping\")\n",
    "ax1.plot(np.arange(len(x2)) + k, x2, 'b-', label=\"EM\")\n",
    "ax1.plot((k, n), (x1[-1], x1[-1]), 'g--')\n",
    "\n",
    "ax1.axis([k - 1, n, x1.min() - 0.5, x1.max() + 5])\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_title('log likelihood (start at ' + str(log_prob_tipping[0]) + ')')\n",
    "ax1.legend(bbox_to_anchor=(0.65, 0.88), loc=2, borderaxespad=0.)\n",
    "# plt.show()\n",
    "\n",
    "y1 = rel_vec_numb_tipping[k:n]\n",
    "y2 = rel_vec_numb_em[k:n]\n",
    "\n",
    "# plt.subplot(2, 1, 2, sharex=True)\n",
    "ax2.plot(np.arange(len(y1)) + k, y1, 'g-', label='Tipping (' + str(rel_vec_numb_tipping[-1]) + ')')\n",
    "ax2.plot(np.arange(len(y2)) + k, y2, 'b-', label='EM (' +  str(rel_vec_numb_em[-1]) + ')')\n",
    "\n",
    "ax2.set_xlabel('Iteration')\n",
    "ax2.set_title('Number of relevant vectors')\n",
    "ax2.legend(bbox_to_anchor=(0.65, 0.8), loc=2, borderaxespad=0.)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(1, len(fr_2_cl.alpha) + 1), fr_2_cl.alpha)\n",
    "plt.scatter(np.arange(1, len(fr_2_cl_em.alpha) + 1), fr_2_cl_em.alpha, c='g')\n",
    "plt.axis([0, 300, -5000, 5000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(1, len(fr_2_cl.w.A[:,0]) + 1), fr_2_cl.w.A[:,0])\n",
    "plt.scatter(np.arange(1, len(fr_2_cl_em.w.A[:,0]) + 1), fr_2_cl_em.w.A[:,0], c='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = fr_2_cl.w.A[:,0]\n",
    "# x = x[np.abs(x) > 1e-3]\n",
    "x = np.select([(np.abs(x) > 1e-3)], [x], [100000] * len(x))\n",
    "plt.scatter(np.arange(1, len(x) + 1), x, label='EM '  + str(len(x)))\n",
    "plt.axis([0, len(x), -7, 7])\n",
    "\n",
    "x = fr_2_cl_em.w.A[:,0]\n",
    "# x = x[np.abs(x) > 1e-3]\n",
    "x = np.select([(np.abs(x) > 1e-3)], [x], [100000] * len(x))\n",
    "plt.scatter(np.arange(1, len(x) + 1), x, marker='x', c='r', label='Tipping '  + str(len(x)))\n",
    "\n",
    "plt.xlabel('Coordinate, i')\n",
    "plt.ylabel('w[i]')\n",
    "plt.title('Weights')\n",
    "# plt.legend(bbox_to_anchor=(0.7, 0.2), loc=2, borderaxespad=0.)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = fr_2_cl.alpha\n",
    "# x = x[np.abs(x) < 1e200]\n",
    "plt.scatter(np.arange(1, len(x) + 1), x, label='EM ')\n",
    "\n",
    "x = fr_2_cl_em.alpha\n",
    "# x = x[np.abs(x) < 1e200]\n",
    "plt.scatter(np.arange(1, len(x) + 1), x, c='r', label='Tipping ' + str(len(x)))\n",
    "\n",
    "plt.axis([0, len(x), -1e4, 1e5])\n",
    "plt.xlabel('Coordinate, i')\n",
    "plt.ylabel('Alpha[i]')\n",
    "plt.legend(bbox_to_anchor=(0.65, 0.8), loc=2, borderaxespad=0.)\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = fr_2_cl.w.A[:,0]\n",
    "plt.scatter(np.arange(1, len(x) + 1), x, marker='x', label='EM '  + str(len(x)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# f, (ax1, ax2) = plt.subplots(2, sharex=True)\n",
    "x = fr_2_cl.w.A[:,0]\n",
    "y = fr_2_cl.alpha\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.axis([-1e-3, 1e-3, -2e4, 4e5])\n",
    "\n",
    "# plt.yticks(np.arange(-1, 50000, 100))\n",
    "# plt.xticks(np.arange(-10, 10, 1))\n",
    "plt.grid()\n",
    "# ax1.scatter(np.arange(len(y)) + 1, y)\n",
    "# ax1.axis([0, 20, -100, 1e5])\n",
    "\n",
    "# ax2.scatter(np.arange(len(x)) + 1, x, marker='x', c='b')\n",
    "# ax2.axis([0, 20, -1e-3, 1e-3])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(2)\n",
    "\n",
    "# alpha to w\n",
    "x = fr_2_cl.w.A[:,0]\n",
    "y = fr_2_cl.alpha\n",
    "\n",
    "ax1.set_title('Alpha for EM ')\n",
    "ax1.scatter(x, y)\n",
    "ax1.axis([-1e-3, 1e-3, -2e4, 4e5])\n",
    "ax1.set_xlabel('Weight')\n",
    "ax1.set_ylabel('Alpha')\n",
    "ax1.grid()\n",
    "\n",
    "# weights\n",
    "\n",
    "x = fr_2_cl.w.A[:,0]\n",
    "# x = x[np.abs(x) > 1e-3]\n",
    "x = np.select([(np.abs(x) > 1e-3)], [x], [100000] * len(x))\n",
    "ax2.scatter(np.arange(1, len(x) + 1), x, label='EM')\n",
    "ax2.axis([0, len(x), -7, 7])\n",
    "\n",
    "x = fr_2_cl_em.w.A[:,0]\n",
    "# x = x[np.abs(x) > 1e-3]\n",
    "x = np.select([(np.abs(x) > 1e-3)], [x], [100000] * len(x))\n",
    "ax2.scatter(np.arange(1, len(x) + 1), x, marker='x', c='r', label='Tipping ')\n",
    "\n",
    "ax2.set_xlabel('Coordinate, i')\n",
    "ax2.set_ylabel('w[i]')\n",
    "ax2.set_title('Weights')\n",
    "ax2.legend(bbox_to_anchor=(0.65, 0.85), loc=2, borderaxespad=0.)\n",
    "ax2.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_exp = 1\n",
    "RMSE = 0\n",
    "for i in range(n_exp):\n",
    "\n",
    "    sinc_cl = RVMRegression(kernel=linear_spline_kernel, number_of_iterations=5000, bias_used=True, calc_prob=False)\n",
    "    a, b = sinc_cl.fit(train_x.reshape((-1, 1)), train_y.reshape((-1, 1)))\n",
    "\n",
    "    pred_y = sinc_cl.predict(valid_x)\n",
    "    plt.scatter(train_x, train_y, c=\"r\", marker='x')\n",
    "    \n",
    "#     plt.scatter(valid_x, pred_y, c='y')\n",
    "    # plt.plot(valid_x, valid_y)\n",
    "    \n",
    "#     plt.scatter(sinc_cl.relevance_x, sinc_cl.relevance_y, c=\"g\")\n",
    "    RMSE += mean_squared_error(valid_y, pred_y) ** 0.5\n",
    "    print('RMSE', mean_squared_error(valid_y, pred_y) ** 0.5)\n",
    "    \n",
    "    x = np.arange(L, R, 0.2)\n",
    "    y = np.sinc(x / np.pi)\n",
    "    \n",
    "    plt.plot(x, y, \"-y\")\n",
    "    \n",
    "    y_p = sinc_cl.predict(x.reshape((-1, 1)))\n",
    "    plt.plot(x, y_p, '-b')\n",
    "    \n",
    "    plt.title('Root-mean-square = ' + str(mean_squared_error(valid_y, pred_y) ** 0.5) + '\\n'\n",
    "          + str(len(sinc_cl.w)) + ' Relevance vectors')\n",
    "    \n",
    "    plt.axis([-10, 10, -0.3, 1.2])\n",
    "#     plt.savefig('unif_samp_sinc_' + str(int(k)) + '.png')\n",
    "    plt.show()\n",
    "\n",
    "print(RMSE / n_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "0.02108**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sinc_cl.score(valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L = -10\n",
    "R = 10\n",
    "# np.random.seed(1)\n",
    "\n",
    "train_x = np.linspace(L, R, 100)\n",
    "train_y = np.sinc(train_x / np.pi)\n",
    "\n",
    "# не забывай про seed!!!\n",
    "train_y += np.random.uniform(-0.1, 0.1, len(train_y))\n",
    "\n",
    "train_x = train_x.reshape((-1, 1))\n",
    "\n",
    "test_x = np.linspace(L, R, 1000)\n",
    "test_x = valid_x.reshape((-1, 1))\n",
    "test_y = np.sinc(valid_x / np.pi).reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_squared_error(valid_y.reshape((-1,)), pred_y) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "((pred_y.reshape((-1,)) - valid_y.reshape(-1,))).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sinc_cl.score(valid_x, valid_y.reshape((-1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start, end = 6000, 10000\n",
    "plt.plot(np.arange(end - start) + start, a[start:end])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl = RVR(kernel=linear_spline_kernel)\n",
    "cl.fit(train_x.reshape((-1, 1)), train_y.reshape((-1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_squared_error(cl.predict(valid_x), valid_y.reshape((-1,))) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sinc_cl.w.A[:,0][sinc_cl.rel_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "((cl.predict(valid_x) - valid_y.reshape(-1,))).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, train_y = make_friedman3(240, noise=1/3)\n",
    "test_x, test_y = make_friedman3(1000)\n",
    "# train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=1-0.24, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25386594887409308"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_2_cl_my = RVMRegression(kernel='rbf', betta=100, alpha=1e-6, gamma=6.3095734448019296e-07)\n",
    "a, b = fr_2_cl_my.fit(train_x, train_y)\n",
    "fr_2_cl_my.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.067364621398883745"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(fr_2_cl_my.predict(test_x), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "al2, w2 = fr_2_cl_my.alpha, fr_2_cl_my.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  2.79037799e-04,   3.23829824e+01,   3.22854488e-03,\n",
       "          6.47866679e+04,   7.49440932e+05,   1.33219656e+05,\n",
       "         -2.06793533e+04,  -5.91796080e+04,  -8.67591436e+05]),\n",
       " array([ 53.12425216,   1.18377345, -52.36903984]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1, w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fr_2_cl_rvr = RVR(kernel=\"rbf\")\n",
    "fr_2_cl_rvr.fit(train_x, train_y)\n",
    "fr_2_cl_rvr.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'gamma':np.linspace(1e-5, 1e-4, 100), 'kernel':['rbf'], 'number_of_iterations':[5000]}\n",
    "clf = GridSearchCV(RVMRegression(), [params])\n",
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_x, cv_y = make_friedman3(n_samples=500, noise=1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {'coef1':np.logspace(-5, 0, 10), 'kernel':['rbf'], 'alpha':np.logspace(-6, -2, 10), \n",
    "          'beta': np.logspace(0, 5, 10)}\n",
    "clf = GridSearchCV(RVR(), [params])\n",
    "clf.fit(cv_x, cv_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'alpha': 1.2589254117941661e-08,\n",
       "  'beta': 100.0,\n",
       "  'coef1': 9.9999999999999995e-07,\n",
       "  'kernel': 'rbf'},\n",
       " 0.21373419318724338)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_, clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.038864520776495284"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(clf.best_estimator_.predict(test_x), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-163.42304446326801"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-67.76118521197445"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_.score(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(test_x[:,1], test_y)\n",
    "plt.scatter(test_x[:,1], clf.best_estimator_.predict(test_x), c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_spline_kernel(x, y):    \n",
    "    ans = []\n",
    "    for x_n in x:\n",
    "        x_n = x_n[0]\n",
    "        tmp = []\n",
    "        for y_n in y:\n",
    "            x_m = y_n[0]\n",
    "            m = min(x_n, x_m)\n",
    "            tmp.append(1 + x_n * x_m + x_n * x_m * m - (x_n + x_m) * (m**2) / 2 + (m**3) / 3)\n",
    "        ans.append(tmp)\n",
    "    \n",
    "    return np.array(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {'C':[10], 'gamma':np.logspace(-9, -6, 10),\n",
    "             'kernel':['linear']}\n",
    "clf = GridSearchCV(SVR(), [parameters])\n",
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.best_params_, clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_squared_error(clf.best_estimator_.predict(test_x), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.best_estimator_.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sinc_svm = SVR(kernel='rbf', C=10, gamma=0.0000001)\n",
    "sinc_svm.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_squared_error(sinc_svm.predict(test_x), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sinc_svm.tol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {'C':np.logspace(-4, -4, 20), 'epsilon':np.logspace(-4, 4, 20)} #, 'epsilon':np.logspace(-5, -2, 20)}\n",
    "clf = GridSearchCV(MySVC(), parameters)\n",
    "clf.fit(train_x.reshape((-1, 1)), train_y.reshape((-1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MySVC(BaseEstimator, RegressorMixin):\n",
    "    def __init__( self, C=1, epsilon=0.01):\n",
    "        self.C = C\n",
    "        self.epsilon = epsilon\n",
    "    def fit( self, X, y ):\n",
    "        kernel = linear_spline_kernel\n",
    "        self.svc_ = SVR(kernel=linear_spline_kernel, C=self.C, epsilon=self.epsilon)\n",
    "        return self.svc_.fit( X, y )\n",
    "    def predict( self, X ):\n",
    "        return self.svc_.predict( X )\n",
    "                         \n",
    "    def score(self, X, y):\n",
    "        return self.svc_.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MySVC().fit(train_x.reshape((-1, 1)), train_y.reshape((-1,))).score(train_x.reshape((-1, 1)), train_y.reshape((-1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.best_score_, clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_squared_error(clf.best_estimator_.predict(valid_x.reshape(-1, 1)), valid_y.reshape(-1,)) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(train_x, train_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.best_estimator_.svc_.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(valid_x, clf.best_estimator_.predict(valid_x.reshape(-1, 1)))\n",
    "plt.plot(valid_x, np.sinc(valid_x / np.pi))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.best_estimator_.svc_.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clsvr = SVR(C=100)\n",
    "clsvr.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clsvr.score(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(clf.best_estimator_.svc_.support_), len(clf.best_estimator_.svc_.support_vectors_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
